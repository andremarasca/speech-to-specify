# Constituidor de Artefatos Narrativos - Environment Variables
# Copy this file to .env and fill in the values

# =============================================================================
# LLM Provider Configuration
# =============================================================================

# Which LLM provider to use: "deepseek", "openai", "anthropic", or "mock"
# Default: deepseek
NARRATE_PROVIDER=deepseek

# =============================================================================
# DeepSeek Configuration (required if NARRATE_PROVIDER=deepseek)
# =============================================================================

# DeepSeek API Key
# Get yours at: https://platform.deepseek.com/
DEEPSEEK_API_KEY=

# DeepSeek Model to use
# Default: deepseek-chat
# Options: deepseek-chat, deepseek-reasoner
DEEPSEEK_MODEL=deepseek-reasoner

# DeepSeek API Base URL (for custom endpoints or proxies)
# Default: https://api.deepseek.com
# DEEPSEEK_BASE_URL=https://api.deepseek.com

# =============================================================================
# OpenAI Configuration (required if NARRATE_PROVIDER=openai)
# =============================================================================

# OpenAI API Key
# Get yours at: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# OpenAI Model to use
# Default: gpt-4
# Options: gpt-5.1, gpt-4, gpt-4-turbo, gpt-4o, gpt-3.5-turbo, etc.
OPENAI_MODEL=gpt-4o-mini

# OpenAI API Base URL (for custom endpoints or proxies)
# Default: https://api.openai.com/v1
# OPENAI_BASE_URL=https://api.openai.com/v1

# =============================================================================
# Anthropic Configuration (required if NARRATE_PROVIDER=anthropic)
# =============================================================================

# Anthropic API Key
# Get yours at: https://console.anthropic.com/
ANTHROPIC_API_KEY=

# Anthropic Model to use
# Default: claude-3-sonnet-20240229
# Options: claude-3-opus-20240229, claude-3-sonnet-20240229, claude-3-haiku-20240307
# ANTHROPIC_MODEL=claude-3-sonnet-20240229

# =============================================================================
# Output Configuration
# =============================================================================

# Directory where execution outputs will be stored
# Default: ./output
NARRATE_OUTPUT_DIR=./output

# =============================================================================
# Runtime Settings
# =============================================================================

# Enable verbose logging (true/false)
# Default: false
# NARRATE_VERBOSE=false

# Request timeout in seconds for LLM calls
# Default: 120
# NARRATE_TIMEOUT=120

# =============================================================================
# Telegram Voice Orchestrator (OATL) Configuration
# =============================================================================

# --- Telegram Bot Configuration ---
# Get your bot token from @BotFather on Telegram
TELEGRAM_BOT_TOKEN=your_bot_token_here

# Your Telegram chat ID (use @userinfobot to find it)
TELEGRAM_ALLOWED_CHAT_ID=123456789

# --- Whisper Configuration ---
# Model: tiny, base, small, small.en, medium, large
# Recommended: small.en for RTX 3050 (4GB VRAM)
WHISPER_MODEL=small

# Device: cuda (GPU) or cpu
WHISPER_DEVICE=cpu

# Language code for transcription
# Default: pt (Portuguese)
# Examples: pt, en, es, fr, de, it, ja, zh
WHISPER_LANGUAGE=pt

# Cache directory for Whisper models (optional)
# WHISPER_CACHE_DIR=~/.cache/whisper

# --- Session Storage ---
SESSIONS_DIR=./sessions

# --- Search and UI Behavior (001-telegram-contract-fix) ---
# Timeout for semantic search requests (seconds)
# Default: 5
SEARCH_TIMEOUT=5

# Page size for paginated search results
# Default: 5
PAGINATION_PAGE_SIZE=5

# Enable fallback help content when UIService is unavailable
# Default: true
HELP_FALLBACK_ENABLED=true

# Enable prompting users to recover interrupted/orphan sessions after restart
# Default: true
ORPHAN_RECOVERY_PROMPT=true

# =============================================================================
# UI Configuration (005-telegram-ux-overhaul)
# =============================================================================

# Telegram message character limit for pagination
# Default: 4096
# TELEGRAM_MESSAGE_LIMIT=4096

# Minimum interval between progress UI updates (seconds)
# Default: 5.0
# UI_PROGRESS_INTERVAL_SECONDS=5.0

# Timeout for long operations before warning user (seconds)
# Default: 300 (5 minutes)
# OPERATION_TIMEOUT_SECONDS=300

# Maximum audio queue size before rate limit warning
# Default: 10
# UI_AUDIO_QUEUE_MAX_SIZE=10

# Timeout for confirmation dialogs before auto-dismiss (seconds)
# Default: 60
# UI_CONFIRMATION_TIMEOUT_SECONDS=60

# =============================================================================
# Oracle Configuration (007-contextual-oracle-feedback)
# =============================================================================

# Directory containing oracle personality markdown files
# Default: prompts/oracles
ORACLES_DIR=prompts/oracles

# Placeholder string for context injection in oracle prompts
# Default: {{CONTEXT}}
ORACLE_PLACEHOLDER={{CONTEXT}}

# Cache TTL in seconds for oracle file scanning
# Use 0 to disable caching (not recommended in production)
# Default: 10
ORACLE_CACHE_TTL=10

# Timeout for LLM API requests in seconds
# Default: 30
LLM_TIMEOUT_SECONDS=30

# --- Oracle LLM Configuration (INDEPENDENT from NARRATE_PROVIDER) ---
# Oracle responses need fast, fluent models (not reasoning models)
# This is separate from NARRATE_PROVIDER which can use slow reasoning models

# LLM provider for oracle feedback: deepseek, openai, anthropic, mock
# Default: deepseek
ORACLE_PROVIDER=openai

# Model to use for oracle responses (should be fast, not reasoning)
# Default: deepseek-chat
# Examples: gpt-5-nano, deepseek-chat, gpt-4o, gpt-4o-mini, claude-3-haiku-20240307
ORACLE_MODEL=gpt-5-nano
