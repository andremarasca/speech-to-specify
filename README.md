# Narrative Artifact Pipeline

A system to transform chaotic text into structured narrative artifacts through a deterministic 3-step LLM prompt chain.

## Overview

The Narrative Artifact Pipeline takes unstructured text input (brainstorms, notes, ideas) and processes it through three sequential transformation steps:

1. **Constitution** - Establishes the fundamental principles and constraints for the narrative
2. **Specification** - Transforms principles into detailed requirements and features
3. **Planning** - Creates an actionable implementation plan

Each step produces a self-documenting artifact with full metadata, enabling future comprehension without external context.

## Installation

### Prerequisites

- Python 3.12+
- An OpenAI or Anthropic API key

### Setup

```bash
# Clone the repository
git clone <repository-url>
cd speech-to-specify

# Create virtual environment
python -m venv .venv

# Activate virtual environment
# On Windows:
.\.venv\Scripts\activate
# On Unix/macOS:
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### Configuration

Create a `.env` file based on `.env.example`:

```bash
cp .env.example .env
```

Configure your preferred LLM provider:

```bash
# For OpenAI (default)
OPENAI_API_KEY=sk-your-api-key-here
NARRATE_PROVIDER=openai

# For Anthropic
ANTHROPIC_API_KEY=sk-ant-your-api-key-here
NARRATE_PROVIDER=anthropic
```

## Usage

### Basic Usage

```bash
python -m src.cli.main path/to/your/notes.txt
```

### Options

```bash
python -m src.cli.main <input-file> [options]

Options:
  -o, --output-dir DIR    Directory for outputs (default: ./output)
  -p, --provider NAME     LLM provider: openai, anthropic, mock (default: openai)
  -v, --verbose           Show detailed progress
  -V, --version           Show version
```

### Examples

```bash
# Process with OpenAI (default)
python -m src.cli.main ./notes/brainstorm.txt

# Use Anthropic instead
python -m src.cli.main ./notes/brainstorm.txt --provider anthropic

# Verbose output with custom output directory
python -m src.cli.main ./notes/brainstorm.txt --output-dir ./my-artifacts --verbose

# Test with mock provider (no API key needed)
python -m src.cli.main ./notes/brainstorm.txt --provider mock --verbose
```

## Output Structure

After running the pipeline, outputs are organized as:

```
output/
â””â”€â”€ executions/
    â””â”€â”€ {execution-id}/
        â”œâ”€â”€ input.md              # Original input with metadata
        â”œâ”€â”€ execution.json        # Execution metadata and status
        â”œâ”€â”€ artifacts/
        â”‚   â”œâ”€â”€ 01_constitution.md
        â”‚   â”œâ”€â”€ 02_specification.md
        â”‚   â””â”€â”€ 03_planning.md
        â””â”€â”€ logs/
            â””â”€â”€ llm_traffic.jsonl # Full LLM interaction log
```

### Artifact Format

Each artifact includes a self-documenting YAML header:

```markdown
---
id: abc123
execution_id: exec-456
step_number: 1
step_name: constitution
predecessor_id: null
created_at: 2024-01-15T10:30:00Z
---

# Constitution

[Generated content here]
```

## Exit Codes

| Code | Meaning |
|------|---------|
| 0 | Success |
| 1 | Usage error (bad arguments) |
| 2 | Configuration error (missing API key) |
| 3 | Validation error (empty input) |
| 4 | LLM error (API failure) |
| 5 | Internal error |

## Development

### Running Tests

```bash
# Run all tests
python -m pytest tests/ -v

# Run with coverage
python -m pytest tests/ -v --cov=src --cov-report=term-missing
```

### Project Structure

```
src/
â”œâ”€â”€ cli/           # Command-line interface
â”œâ”€â”€ lib/           # Shared utilities
â”œâ”€â”€ models/        # Domain entities
â””â”€â”€ services/
    â”œâ”€â”€ llm/       # LLM provider adapters
    â””â”€â”€ persistence/  # Storage implementations
tests/
â”œâ”€â”€ unit/          # Unit tests
â”œâ”€â”€ contract/      # Contract tests for interfaces
â””â”€â”€ integration/   # End-to-end tests
prompts/           # LLM prompt templates
```

## License

See [LICENSE](LICENSE) for details.

---

# Telegram Voice Orchestrator (OATL)

Remote voice-to-text orchestration via Telegram with 100% local processing.

## Overview

The Voice Orchestrator allows you to:
1. Send voice messages to a Telegram bot from anywhere
2. Have them automatically transcribed locally using Whisper (GPU-accelerated)
3. Feed transcripts to the Narrative Artifact Pipeline

**Key Principles:**
- **Data Sovereignty** - All processing happens locally; Telegram is just a channel
- **Explicit State** - Session state persisted as JSON for auditability
- **Immutability** - Sessions are locked after finalization

## Prerequisites

- NVIDIA GPU with CUDA support (recommended: RTX 3050+ with 4GB+ VRAM)
- Telegram Bot Token (from @BotFather)
- Your Telegram Chat ID

## Configuration

Add to your `.env` file:

```bash
# Telegram Configuration
TELEGRAM_BOT_TOKEN=your-bot-token-here
TELEGRAM_ALLOWED_CHAT_ID=your-chat-id

# Whisper Configuration
WHISPER_MODEL=small.en  # Options: tiny, base, small, small.en, medium, large
WHISPER_DEVICE=cuda     # cuda or cpu
WHISPER_FP16=true       # Use FP16 for faster GPU inference

# Sessions Directory
SESSIONS_DIR=./sessions
```

## Running the Daemon

```bash
# Start the voice orchestrator daemon
python -m src.cli.daemon

# With verbose logging
python -m src.cli.daemon --verbose
```

## Telegram Commands

| Command | Description |
|---------|-------------|
| `/start` | Start new voice capture session |
| `/done` or `/finish` | Finalize session and begin transcription |
| `/status` | Show current session status |
| `/transcripts` | Retrieve transcription text |
| `/process` | Send transcripts to narrative pipeline |
| `/list` | List session files |
| `/get <file>` | Download specific file |
| `/help` | Show available commands |

## Typical Workflow

1. **Start a session:**
   - Send `/start` to the bot
   - Bot confirms session creation with ID

2. **Record voice notes:**
   - Send voice messages one at a time
   - Bot confirms receipt with sequence number

3. **Finalize and transcribe:**
   - Send `/done` to finalize
   - Bot transcribes all audio locally using Whisper
   - Progress updates sent for each file

4. **Review results:**
   - `/transcripts` - View all transcriptions
   - `/list` - See session files
   - `/get transcripts/001_audio.txt` - Download specific file

5. **Process through pipeline (optional):**
   - `/process` - Run narrative pipeline on transcripts
   - Bot sends results when complete

## Session Structure

```
sessions/
â””â”€â”€ {session-id}/           # e.g., 2025-12-18_14-30-00
    â”œâ”€â”€ metadata.json       # Session state and audio entries
    â”œâ”€â”€ audio/
    â”‚   â”œâ”€â”€ 001_audio.ogg
    â”‚   â”œâ”€â”€ 002_audio.ogg
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ transcripts/
    â”‚   â”œâ”€â”€ 001_audio.txt
    â”‚   â”œâ”€â”€ 002_audio.txt
    â”‚   â””â”€â”€ consolidated.txt
    â””â”€â”€ process/
        â”œâ”€â”€ input.txt       # Consolidated for pipeline
        â””â”€â”€ output/         # Pipeline artifacts
```

## Session States

| State | Description |
|-------|-------------|
| `COLLECTING` | Session open, accepting voice messages |
| `TRANSCRIBING` | Finalized, transcription in progress |
| `TRANSCRIBED` | All audio transcribed, ready for processing |
| `PROCESSING` | Downstream pipeline running |
| `PROCESSED` | All processing complete |
| `ERROR` | Unrecoverable error occurred |

## Contextual Oracle Feedback (007-contextual-oracle-feedback)

After transcription, you can request AI feedback from multiple "oracle" personalities. Each oracle analyzes your transcripts with a distinct perspective.

### Oracle Buttons

After transcription completes, you'll see buttons for available oracles:
- ðŸ”® **CÃ©tico** - Skeptical analysis, identifies risks and assumptions
- ðŸ”® **VisionÃ¡rio** - Expansive thinking, explores possibilities  
- ðŸ”® **Otimista** - Finds strengths and constructive paths forward

Click any oracle button to receive contextual feedback that references your transcript content.

### Configuration

Add to your `.env` file:

```bash
# Oracle Configuration
ORACLES_DIR=prompts/oracles    # Directory containing oracle files
ORACLE_PLACEHOLDER={{CONTEXT}} # Placeholder for context injection
ORACLE_CACHE_TTL=10            # Cache refresh interval (seconds)
LLM_TIMEOUT_SECONDS=30         # Timeout for LLM requests
```

### Adding Custom Oracles

Create a new `.md` file in `prompts/oracles/`:

```markdown
# My Custom Oracle

You are a [personality description].

{{CONTEXT}}

Provide feedback in [specific format].
```

The oracle appears automatically in the keyboard after the cache refreshes (~10 seconds).

### LLM History Toggle

The **ðŸ”— HistÃ³rico: ON** button controls "spiral feedback":
- **ON** (default): Subsequent oracle requests include prior oracle responses
- **OFF**: Each oracle only sees transcripts, not prior LLM responses

This allows iterative analysis where oracles build upon each other's insights.

### Documentation

- [Tutorial: Adding Oracles](docs/tutorial_adding_oracles.md)
- [Tutorial: Context Management](docs/tutorial_context_management.md)

## Interactive UI Features (005-telegram-ux-overhaul)

The bot includes an enhanced interactive experience with inline keyboards:

### Zero-Command Flow
- Sessions auto-create when you send your first voice message
- Inline keyboard buttons replace most text commands
- **Finalize**, **Status**, and **Help** buttons available on all messages

### Progress Feedback
- Real-time progress updates during transcription
- Visual progress bar: `â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘ 50%`
- Step descriptions for each processing phase

### Error Recovery
- User-friendly error messages (no stack traces)
- Recovery buttons for common issues
- Retry option for transient failures

### Session Protection
- Confirmation dialog when starting new session with active audio
- Options: Finalize current, Start new, or Return to active

### Timeout Handling
- Notification for long-running operations
- Options to continue waiting or cancel

### Preferences
- `/preferences` - View/change UI settings
- `/preferences simple` - Enable simplified UI (no emojis)
- `/preferences normal` - Enable normal UI (with emojis)

### Help System
- Contextual help button in all keyboards
- Help content varies based on current operation